{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:57:43.942994Z",
     "start_time": "2024-04-09T12:57:43.140678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # For multi-GPU\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:57:48.057464Z",
     "start_time": "2024-04-09T12:57:47.463411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server-171/anaconda3/envs/eeg-gpu/lib/python3.9/site-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Rearrange-1               [-1, 4, 448]               0\n",
      "            Linear-2               [-1, 4, 256]         114,944\n",
      "           Dropout-3               [-1, 5, 256]               0\n",
      "         LayerNorm-4               [-1, 5, 256]             512\n",
      "            Linear-5              [-1, 5, 3072]         786,432\n",
      "           Softmax-6              [-1, 8, 5, 5]               0\n",
      "           Dropout-7              [-1, 8, 5, 5]               0\n",
      "            Linear-8               [-1, 5, 256]         262,400\n",
      "           Dropout-9               [-1, 5, 256]               0\n",
      "        Attention-10               [-1, 5, 256]               0\n",
      "          PreNorm-11               [-1, 5, 256]               0\n",
      "        LayerNorm-12               [-1, 5, 256]             512\n",
      "           Linear-13              [-1, 5, 1024]         263,168\n",
      "             GELU-14              [-1, 5, 1024]               0\n",
      "          Dropout-15              [-1, 5, 1024]               0\n",
      "           Linear-16               [-1, 5, 256]         262,400\n",
      "          Dropout-17               [-1, 5, 256]               0\n",
      "      FeedForward-18               [-1, 5, 256]               0\n",
      "          PreNorm-19               [-1, 5, 256]               0\n",
      "        LayerNorm-20               [-1, 5, 256]             512\n",
      "           Linear-21              [-1, 5, 3072]         786,432\n",
      "          Softmax-22              [-1, 8, 5, 5]               0\n",
      "          Dropout-23              [-1, 8, 5, 5]               0\n",
      "           Linear-24               [-1, 5, 256]         262,400\n",
      "          Dropout-25               [-1, 5, 256]               0\n",
      "        Attention-26               [-1, 5, 256]               0\n",
      "          PreNorm-27               [-1, 5, 256]               0\n",
      "        LayerNorm-28               [-1, 5, 256]             512\n",
      "           Linear-29              [-1, 5, 1024]         263,168\n",
      "             GELU-30              [-1, 5, 1024]               0\n",
      "          Dropout-31              [-1, 5, 1024]               0\n",
      "           Linear-32               [-1, 5, 256]         262,400\n",
      "          Dropout-33               [-1, 5, 256]               0\n",
      "      FeedForward-34               [-1, 5, 256]               0\n",
      "          PreNorm-35               [-1, 5, 256]               0\n",
      "        LayerNorm-36               [-1, 5, 256]             512\n",
      "           Linear-37              [-1, 5, 3072]         786,432\n",
      "          Softmax-38              [-1, 8, 5, 5]               0\n",
      "          Dropout-39              [-1, 8, 5, 5]               0\n",
      "           Linear-40               [-1, 5, 256]         262,400\n",
      "          Dropout-41               [-1, 5, 256]               0\n",
      "        Attention-42               [-1, 5, 256]               0\n",
      "          PreNorm-43               [-1, 5, 256]               0\n",
      "        LayerNorm-44               [-1, 5, 256]             512\n",
      "           Linear-45              [-1, 5, 1024]         263,168\n",
      "             GELU-46              [-1, 5, 1024]               0\n",
      "          Dropout-47              [-1, 5, 1024]               0\n",
      "           Linear-48               [-1, 5, 256]         262,400\n",
      "          Dropout-49               [-1, 5, 256]               0\n",
      "      FeedForward-50               [-1, 5, 256]               0\n",
      "          PreNorm-51               [-1, 5, 256]               0\n",
      "        LayerNorm-52               [-1, 5, 256]             512\n",
      "           Linear-53              [-1, 5, 3072]         786,432\n",
      "          Softmax-54              [-1, 8, 5, 5]               0\n",
      "          Dropout-55              [-1, 8, 5, 5]               0\n",
      "           Linear-56               [-1, 5, 256]         262,400\n",
      "          Dropout-57               [-1, 5, 256]               0\n",
      "        Attention-58               [-1, 5, 256]               0\n",
      "          PreNorm-59               [-1, 5, 256]               0\n",
      "        LayerNorm-60               [-1, 5, 256]             512\n",
      "           Linear-61              [-1, 5, 1024]         263,168\n",
      "             GELU-62              [-1, 5, 1024]               0\n",
      "          Dropout-63              [-1, 5, 1024]               0\n",
      "           Linear-64               [-1, 5, 256]         262,400\n",
      "          Dropout-65               [-1, 5, 256]               0\n",
      "      FeedForward-66               [-1, 5, 256]               0\n",
      "          PreNorm-67               [-1, 5, 256]               0\n",
      "        LayerNorm-68               [-1, 5, 256]             512\n",
      "           Linear-69              [-1, 5, 3072]         786,432\n",
      "          Softmax-70              [-1, 8, 5, 5]               0\n",
      "          Dropout-71              [-1, 8, 5, 5]               0\n",
      "           Linear-72               [-1, 5, 256]         262,400\n",
      "          Dropout-73               [-1, 5, 256]               0\n",
      "        Attention-74               [-1, 5, 256]               0\n",
      "          PreNorm-75               [-1, 5, 256]               0\n",
      "        LayerNorm-76               [-1, 5, 256]             512\n",
      "           Linear-77              [-1, 5, 1024]         263,168\n",
      "             GELU-78              [-1, 5, 1024]               0\n",
      "          Dropout-79              [-1, 5, 1024]               0\n",
      "           Linear-80               [-1, 5, 256]         262,400\n",
      "          Dropout-81               [-1, 5, 256]               0\n",
      "      FeedForward-82               [-1, 5, 256]               0\n",
      "          PreNorm-83               [-1, 5, 256]               0\n",
      "        LayerNorm-84               [-1, 5, 256]             512\n",
      "           Linear-85              [-1, 5, 3072]         786,432\n",
      "          Softmax-86              [-1, 8, 5, 5]               0\n",
      "          Dropout-87              [-1, 8, 5, 5]               0\n",
      "           Linear-88               [-1, 5, 256]         262,400\n",
      "          Dropout-89               [-1, 5, 256]               0\n",
      "        Attention-90               [-1, 5, 256]               0\n",
      "          PreNorm-91               [-1, 5, 256]               0\n",
      "        LayerNorm-92               [-1, 5, 256]             512\n",
      "           Linear-93              [-1, 5, 1024]         263,168\n",
      "             GELU-94              [-1, 5, 1024]               0\n",
      "          Dropout-95              [-1, 5, 1024]               0\n",
      "           Linear-96               [-1, 5, 256]         262,400\n",
      "          Dropout-97               [-1, 5, 256]               0\n",
      "      FeedForward-98               [-1, 5, 256]               0\n",
      "          PreNorm-99               [-1, 5, 256]               0\n",
      "     Transformer-100               [-1, 5, 256]               0\n",
      "       LayerNorm-101                  [-1, 256]             512\n",
      "          Linear-102                    [-1, 2]             514\n",
      "================================================================\n",
      "Total params: 9,568,514\n",
      "Trainable params: 9,568,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.05\n",
      "Params size (MB): 36.50\n",
      "Estimated Total Size (MB): 38.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from model import model_dict\n",
    "m = model_dict['simplevit']\n",
    "\n",
    "from torcheeg.models import ArjunViT\n",
    "m = ArjunViT(\n",
    "    num_electrodes=14,\n",
    "    chunk_size=128,\n",
    "    t_patch_size=128//4,\n",
    "    hid_channels=256,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    head_channels=128,\n",
    "    mlp_channels=1024,\n",
    "    embed_dropout=0.2,\n",
    "    dropout=0.1\n",
    ")\n",
    "summary(m.cuda(), (14, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:58:31.597779Z",
     "start_time": "2024-04-09T12:58:29.169416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-09 20:58:30] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/deap_raw_normalized_75_percent_overlap.\n",
      "[2024-04-09 20:58:30] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/seed_binary_raw_normalized_75_percent_overlap.\n",
      "[2024-04-09 20:58:31] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/dreamer_raw_normalized_75_percent_overlap.\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "deap_raw, seed_raw, dreamer_raw = prepare_dataset(feature_type='raw_normalized', class_type='binary', overlap_percent=75)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# deap_raw_loader = DataLoader(CustomDataset(deap_raw), batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "# seed_raw_loader = DataLoader(CustomDataset(seed_raw), batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "# dreamer_raw_loader = DataLoader(CustomDataset(dreamer_raw), batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "trainloaders, valloaders, testloaders = prepare_dataloaders([deap_raw, seed_raw, dreamer_raw], batch_size=BATCH_SIZE, test_ratio=0.2)\n",
    "deap_raw_train, deap_raw_val, deap_raw_test = trainloaders[0], valloaders[0], testloaders[0]\n",
    "seed_raw_train, seed_raw_val, seed_raw_test = trainloaders[1], valloaders[1], testloaders[1]\n",
    "dreamer_raw_train, dreamer_raw_val, dreamer_raw_test = trainloaders[2], valloaders[2], testloaders[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:58:51.983540Z",
     "start_time": "2024-04-09T12:58:50.555070Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-09 20:58:50] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/deap_de_grid_75_percent_overlap.\n",
      "[2024-04-09 20:58:50] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/seed_binary_de_grid_75_percent_overlap.\n",
      "[2024-04-09 20:58:51] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/dreamer_de_grid_75_percent_overlap.\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "deap_grid, seed_grid, dreamer_grid = prepare_dataset(feature_type='de_grid', class_type='binary', overlap_percent=75)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# deap_grid_loader = DataLoader(CustomDataset(deap_grid), batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "# seed_grid_loader = DataLoader(CustomDataset(seed_grid), batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "# dreamer_grid_loader = DataLoader(CustomDataset(dreamer_grid), batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "trainloaders, valloaders, testloaders = prepare_dataloaders([deap_grid, seed_grid, dreamer_grid], batch_size=BATCH_SIZE, test_ratio=0.2)\n",
    "deap_grid_train, deap_grid_val, deap_grid_test = trainloaders[0], valloaders[0], testloaders[0]\n",
    "seed_grid_train, seed_grid_val, seed_grid_test = trainloaders[1], valloaders[1], testloaders[1]\n",
    "dreamer_grid_train, dreamer_grid_val, dreamer_grid_test = trainloaders[2], valloaders[2], testloaders[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-09 21:25:07] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/deap_raw_normalized_75_percent_overlap.\n",
      "[2024-04-09 21:25:07] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/seed_binary_raw_normalized_75_percent_overlap.\n",
      "[2024-04-09 21:25:08] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/dreamer_raw_normalized_75_percent_overlap.\n",
      "[2024-04-09 21:25:09] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/deap_de_grid_75_percent_overlap.\n",
      "[2024-04-09 21:25:09] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/seed_binary_de_grid_75_percent_overlap.\n",
      "[2024-04-09 21:25:10] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from ../processed_data/dreamer_de_grid_75_percent_overlap.\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "raw_datasets = prepare_dataset(feature_type='raw_normalized', class_type='binary', overlap_percent=75)\n",
    "raw_trainloaders, raw_valloaders, raw_testloaders = prepare_dataloaders(\n",
    "    raw_datasets, 64, 0.2\n",
    ")\n",
    "\n",
    "grid_datasets = prepare_dataset(feature_type='de_grid', class_type='binary', overlap_percent=75)\n",
    "grid_trainloaders, grid_valloaders, grid_testloaders = prepare_dataloaders(\n",
    "    grid_datasets, 64, 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dreamer'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloaders = list(zip(raw_trainloaders, grid_trainloaders))\n",
    "trainloader = trainloaders[2]\n",
    "raw_trainloader, grid_trainloader = trainloader\n",
    "dataset = raw_trainloader.dataset.dataset.__dict__['dataset']\n",
    "dataset_name = dataset.__class__.__name__.lower().replace('dataset', '').replace('binary', '')\n",
    "dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T13:03:03.956466Z",
     "start_time": "2024-04-09T13:03:03.554053Z"
    }
   },
   "outputs": [],
   "source": [
    "from torcheeg.models import ArjunViT\n",
    "from torcheeg.trainers import ClassifierTrainer\n",
    "\n",
    "def load_checkpoint_old(checkpoint_path, chunk_size, num_channel, patch_per_chunk, num_classes):\n",
    "\n",
    "    # Initialize the model with parameters\n",
    "    model = ArjunViT(chunk_size=chunk_size,\n",
    "                     t_patch_size=chunk_size // patch_per_chunk,\n",
    "                     num_electrodes=num_channel,\n",
    "                     num_classes=num_classes)\n",
    "\n",
    "    # Load the checkpoint\n",
    "    trainer = ClassifierTrainer.load_from_checkpoint(checkpoint_path, model=model, num_classes=num_classes)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T13:03:15.436724Z",
     "start_time": "2024-04-09T13:03:15.434338Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torcheeg.trainers import ClassifierTrainer\n",
    "\n",
    "def load_checkpoint(checkpoint_path):\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    hparams = checkpoint['hyper_parameters']\n",
    "    trainer = ClassifierTrainer(**hparams)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEAP Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T13:04:01.473259Z",
     "start_time": "2024-04-09T13:04:01.097604Z"
    }
   },
   "outputs": [],
   "source": [
    "# deap\n",
    "checkpoint_path = '../federated_construct_2/arjunvit_binary_logs/75_percent_overlap/deap/fit/lightning_logs/version_1/checkpoints/last.ckpt'\n",
    "deap_trainer = load_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(deap_trainer.test(deap_train, enable_checkpointing=False, logger=False))\n",
    "# print(deap_trainer.test(deap_val, enable_checkpointing=False, logger=False))\n",
    "# print(deap_trainer.test(deap_test, enable_checkpointing=False, logger=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deap_trainer.test(deap_loader, enable_checkpointing=False, logger=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEED Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T13:04:35.060083Z",
     "start_time": "2024-04-09T13:04:34.981996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server-171/anaconda3/envs/eeg-gpu/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "# seed\n",
    "checkpoint_path = '../federated_construct_2/arjunvit_binary_logs/75_percent_overlap/seed/fit/lightning_logs/version_1/checkpoints/last.ckpt'\n",
    "seed_trainer = load_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(seed_trainer.test(seed_train, enable_checkpointing=False, logger=False))\n",
    "# print(seed_trainer.test(seed_val, enable_checkpointing=False, logger=False))\n",
    "# print(seed_trainer.test(seed_test, enable_checkpointing=False, logger=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_trainer.test(seed_loader, enable_checkpointing=False, logger=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DREAMER Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T13:04:54.401288Z",
     "start_time": "2024-04-09T13:04:54.257828Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server-171/anaconda3/envs/eeg-gpu/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "# dreamer\n",
    "checkpoint_path = '../federated_construct_2/arjunvit_binary_logs/75_percent_overlap/dreamer/fit/lightning_logs/version_1/checkpoints/last.ckpt'\n",
    "dreamer_trainer = load_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dreamer_trainer.test(dreamer_train, enable_checkpointing=False, logger=False))\n",
    "# print(dreamer_trainer.test(dreamer_val, enable_checkpointing=False, logger=False))\n",
    "# print(dreamer_trainer.test(dreamer_test, enable_checkpointing=False, logger=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dreamer_trainer.test(dreamer_loader, enable_checkpointing=False, logger=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torcheeg.models import FBCCNN\n",
    "from torcheeg import transforms\n",
    "\n",
    "from torcheeg.datasets.constants.emotion_recognition.deap import DEAP_CHANNEL_LOCATION_DICT, DEAP_CHANNEL_LIST\n",
    "from torcheeg.datasets.constants.emotion_recognition.seed import SEED_CHANNEL_LOCATION_DICT, SEED_CHANNEL_LIST\n",
    "from torcheeg.datasets.constants.emotion_recognition.dreamer import DREAMER_CHANNEL_LOCATION_DICT, DREAMER_CHANNEL_LIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "t = transforms.Compose([\n",
    "    transforms.BandPowerSpectralDensity(),\n",
    "    transforms.ToGrid(DEAP_CHANNEL_LOCATION_DICT),\n",
    "])\n",
    "\n",
    "t = transforms.Compose([\n",
    "    transforms.BandDifferentialEntropy(),\n",
    "    transforms.ToGrid(DEAP_CHANNEL_LOCATION_DICT),\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_offline_kd(epoch, teacher_model, student_model, data_raw, data_grid, temperature=1.0, alpha=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion_hard = nn.CrossEntropyLoss().to(device)\n",
    "    criterion_soft = nn.KLDivLoss(reduction='batchmean').to(device)\n",
    "    \n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "    student_model.train()  # only update student model parameters\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(zip(data_raw, data_grid)), total=len(data_raw), desc=f\"Training Epoch {epoch}\", leave=True)\n",
    "    for i, (raw, grid) in progress_bar:\n",
    "        # Unpacking raw and grid data\n",
    "        X_raw, y_raw = raw\n",
    "        X_grid, y_grid = grid\n",
    "        \n",
    "        X_raw, y_raw = X_raw.to(device), y_raw.to(device)\n",
    "        X_grid, y_grid = X_grid.to(device), y_grid.to(device)\n",
    "        \n",
    "        assert torch.equal(y_raw, y_grid), \"Both y must be equal\"\n",
    "        y = y_raw\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass teacher model\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(X_raw)\n",
    "\n",
    "        # Forward pass student model\n",
    "        student_outputs = student_model(X_grid)\n",
    "\n",
    "        # Calculate the loss for hard label\n",
    "        loss_hard = criterion_hard(student_outputs, y)\n",
    "\n",
    "        # Calculate the loss for soft label\n",
    "        loss_soft = criterion_soft(\n",
    "            F.log_softmax(student_outputs / temperature, dim=1),\n",
    "            F.softmax(teacher_outputs / temperature, dim=1)\n",
    "        )\n",
    "\n",
    "        # Backpropagation\n",
    "        loss = alpha * loss_soft + (1 - alpha) * loss_hard\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(student_outputs.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        current_loss = running_loss / (i + 1)\n",
    "        accuracy = 100 * correct / total\n",
    "        progress_bar.set_postfix(Loss=f'{current_loss:.4f}', Accuracy=f'{accuracy:.2f}%')\n",
    "\n",
    "    average_loss = running_loss / len(data_raw)\n",
    "    accuracy = 100 * correct / total\n",
    "    return average_loss, accuracy\n",
    "\n",
    "def validate_offline_kd(epoch, teacher_model, student_model, data_raw, data_grid, temperature=1.0, alpha=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion_hard = nn.CrossEntropyLoss().to(device)\n",
    "    criterion_soft = nn.KLDivLoss(reduction='batchmean').to(device)\n",
    "    \n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    student_model.eval()  # Set the student model to evaluation mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(zip(data_raw, data_grid)), total=len(data_raw), desc=f\"Validation Epoch {epoch}\", leave=True)\n",
    "    with torch.no_grad():  # No gradients needed\n",
    "        for i, (raw, grid) in progress_bar:\n",
    "            # Unpacking raw and grid data\n",
    "            X_raw, y_raw = raw\n",
    "            X_grid, y_grid = grid\n",
    "            \n",
    "            X_raw, y_raw = X_raw.to(device), y_raw.to(device)\n",
    "            X_grid, y_grid = X_grid.to(device), y_grid.to(device)\n",
    "            \n",
    "            assert torch.equal(y_raw, y_grid), \"Both y must be equal\"\n",
    "            y = y_raw\n",
    "\n",
    "            # Forward pass\n",
    "            teacher_outputs = teacher_model(X_raw)\n",
    "            student_outputs = student_model(X_grid)\n",
    "\n",
    "            # Loss calculation\n",
    "            loss_hard = criterion_hard(student_outputs, y)\n",
    "            loss_soft = criterion_soft(\n",
    "                F.log_softmax(student_outputs / temperature, dim=1),\n",
    "                F.softmax(teacher_outputs / temperature, dim=1)\n",
    "            )\n",
    "\n",
    "            loss = alpha * loss_soft + (1 - alpha) * loss_hard\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            current_loss = running_loss / (i + 1)\n",
    "            accuracy = 100 * correct / total\n",
    "            progress_bar.set_postfix(Loss=f'{current_loss:.4f}', Accuracy=f'{accuracy:.2f}%')\n",
    "\n",
    "    average_loss = running_loss / len(data_raw)\n",
    "    accuracy = 100 * correct / total\n",
    "    return average_loss, accuracy\n",
    "\n",
    "def test_model(model, dataloader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Testing\", leave=True)\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in progress_bar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            current_loss = running_loss / (i + 1)\n",
    "            accuracy = 100 * correct / total\n",
    "            progress_bar.set_postfix(Loss=f'{current_loss:.4f}', Accuracy=f'{accuracy:.2f}%')\n",
    "\n",
    "    average_loss = running_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████| 768/768 [00:16<00:00, 46.25it/s, Accuracy=62.41%, Loss=0.3684]\n",
      "Validation Epoch 0: 100%|██████████| 192/192 [00:03<00:00, 59.96it/s, Accuracy=68.14%, Loss=0.3427]\n",
      "Training Epoch 1: 100%|██████████| 768/768 [00:17<00:00, 44.02it/s, Accuracy=75.97%, Loss=0.3148]\n",
      "Validation Epoch 1: 100%|██████████| 192/192 [00:02<00:00, 66.47it/s, Accuracy=78.52%, Loss=0.3059]\n",
      "Training Epoch 2: 100%|██████████| 768/768 [00:15<00:00, 49.61it/s, Accuracy=84.86%, Loss=0.2719]\n",
      "Validation Epoch 2: 100%|██████████| 192/192 [00:04<00:00, 47.16it/s, Accuracy=82.19%, Loss=0.2890]\n",
      "Training Epoch 3: 100%|██████████| 768/768 [00:18<00:00, 42.00it/s, Accuracy=89.81%, Loss=0.2463]\n",
      "Validation Epoch 3: 100%|██████████| 192/192 [00:03<00:00, 57.56it/s, Accuracy=84.76%, Loss=0.2788]\n",
      "Training Epoch 4: 100%|██████████| 768/768 [00:20<00:00, 38.29it/s, Accuracy=92.29%, Loss=0.2318]\n",
      "Validation Epoch 4: 100%|██████████| 192/192 [00:04<00:00, 45.22it/s, Accuracy=85.89%, Loss=0.2732]\n",
      "Testing: 100%|██████████| 240/240 [00:03<00:00, 64.69it/s, Accuracy=68.34%, Loss=0.5844] \n",
      "Testing: 100%|██████████| 240/240 [00:02<00:00, 82.26it/s, Accuracy=85.71%, Loss=0.3979] \n"
     ]
    }
   ],
   "source": [
    "data_raw_train = deap_raw_train\n",
    "data_raw_val = deap_raw_val\n",
    "data_raw_test = deap_raw_test\n",
    "\n",
    "data_grid_train = deap_grid_train\n",
    "data_grid_val = deap_grid_val\n",
    "data_grid_test = deap_grid_test\n",
    "\n",
    "teacher_model = deap_trainer\n",
    "student_model = FBCCNN(num_classes=2, in_channels=4, grid_size=(9, 9))\n",
    "\n",
    "# Lists to store metrics for each epoch\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    # Training\n",
    "    train_loss, train_accuracy = train_offline_kd(epoch, teacher_model, student_model, data_raw_train, data_grid_train, temperature=1.0, alpha=0.5)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_accuracy = validate_offline_kd(epoch, teacher_model, student_model, data_raw_val, data_grid_val, temperature=1.0, alpha=0.5)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Testing\n",
    "test_loss_teacher, test_accuracy_teacher = test_model(teacher_model, data_raw_test)\n",
    "test_loss_student, test_accuracy_student = test_model(student_model, data_grid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62.406412760416664, 75.970458984375, 84.85921223958333, 89.80712890625, 92.29329427083333]\n",
      "[68.1396484375, 78.52376302083333, 82.19401041666667, 84.75748697916667, 85.888671875]\n",
      "68.33984375\n",
      "85.70963541666667\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracies)\n",
    "print(val_accuracies)\n",
    "print(test_accuracy_teacher)\n",
    "print(test_accuracy_student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_online_kd(epoch, teacher_model, student_model, data_raw, data_grid, temperature=1.0, alpha=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion_hard = nn.CrossEntropyLoss().to(device)\n",
    "    criterion_soft = nn.KLDivLoss(reduction='batchmean').to(device)\n",
    "    \n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    # Separate optimizers for teacher and student models\n",
    "    optimizer_teacher = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
    "    optimizer_student = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "    \n",
    "    student_model.train()\n",
    "    teacher_model.train()\n",
    "    \n",
    "    running_loss_student = 0.0\n",
    "    running_loss_teacher = 0.0\n",
    "    correct_student = 0\n",
    "    correct_teacher = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(zip(data_raw, data_grid)), total=len(data_raw), desc=f\"Training Epoch {epoch}\", leave=True)\n",
    "    for i, (raw, grid) in progress_bar:\n",
    "        # Unpacking raw and grid data\n",
    "        X_raw, y_raw = raw\n",
    "        X_grid, y_grid = grid\n",
    "        \n",
    "        X_raw, y_raw = X_raw.to(device), y_raw.to(device)\n",
    "        X_grid, y_grid = X_grid.to(device), y_grid.to(device)\n",
    "        \n",
    "        assert torch.equal(y_raw, y_grid), \"Both y must be equal\"\n",
    "        y = y_raw\n",
    "        \n",
    "        optimizer_teacher.zero_grad()\n",
    "        optimizer_student.zero_grad()\n",
    "\n",
    "        # Forward pass for both teacher and student model\n",
    "        teacher_outputs = teacher_model(X_raw)\n",
    "        student_outputs = student_model(X_grid)\n",
    "\n",
    "        # Calculate the hard loss\n",
    "        loss_teacher_hard = criterion_hard(teacher_outputs, y)\n",
    "        loss_student_hard = criterion_hard(student_outputs, y)\n",
    "\n",
    "        # Calculate the soft loss\n",
    "        loss_soft = criterion_soft(\n",
    "            F.log_softmax(student_outputs / temperature, dim=1),\n",
    "            F.softmax(teacher_outputs / temperature, dim=1)\n",
    "        )\n",
    "\n",
    "        # Backpropagation\n",
    "        # For teacher\n",
    "        loss_teacher = alpha * loss_soft.detach() + (1 - alpha) * loss_teacher_hard\n",
    "        loss_teacher.backward(retain_graph=True)\n",
    "        \n",
    "        # For student\n",
    "        loss_student = alpha * loss_soft + (1 - alpha) * loss_student_hard\n",
    "        loss_student.backward()\n",
    "        \n",
    "        optimizer_teacher.step()\n",
    "        optimizer_student.step()\n",
    "\n",
    "        running_loss_student += loss_student.item()\n",
    "        running_loss_teacher += loss_teacher.item()\n",
    "        _, predicted_student = torch.max(student_outputs.data, 1)\n",
    "        _, predicted_teacher = torch.max(teacher_outputs.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct_student += (predicted_student == y).sum().item()\n",
    "        correct_teacher += (predicted_teacher == y).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        accuracy_student = 100 * correct_student / total\n",
    "        accuracy_teacher = 100 * correct_teacher / total\n",
    "        current_loss_student = running_loss_student / (i + 1)\n",
    "        current_loss_teacher = running_loss_teacher / (i + 1)\n",
    "        \n",
    "        progress_bar.set_postfix(Student_Loss=f'{current_loss_student:.4f}', Student_Accuracy=f'{accuracy_student:.2f}%', Teacher_Loss=f'{current_loss_teacher:.4f}', Teacher_Accuracy=f'{accuracy_teacher:.2f}%')\n",
    "\n",
    "    average_loss_student = running_loss_student / len(data_raw)\n",
    "    average_loss_teacher = running_loss_teacher / len(data_raw)\n",
    "    accuracy_student = 100 * correct_student / total\n",
    "    accuracy_teacher = 100 * correct_teacher / total\n",
    "    return average_loss_student, average_loss_teacher, accuracy_student, accuracy_teacher\n",
    "\n",
    "def validate_online_kd(epoch, teacher_model, student_model, data_raw, data_grid, temperature=1.0, alpha=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion_hard = torch.nn.CrossEntropyLoss().to(device)\n",
    "    criterion_soft = torch.nn.KLDivLoss(reduction='batchmean').to(device)\n",
    "    \n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    student_model.eval()\n",
    "    teacher_model.eval()\n",
    "    \n",
    "    running_loss_student = 0.0\n",
    "    running_loss_teacher = 0.0\n",
    "    correct_student = 0\n",
    "    correct_teacher = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(zip(data_raw, data_grid)), total=len(data_raw), desc=f\"Validation Epoch {epoch}\", leave=True)\n",
    "    with torch.no_grad():\n",
    "        for i, (raw, grid) in progress_bar:\n",
    "            # Unpacking raw and grid data\n",
    "            X_raw, y_raw = raw\n",
    "            X_grid, y_grid = grid\n",
    "            \n",
    "            X_raw, y_raw = X_raw.to(device), y_raw.to(device)\n",
    "            X_grid, y_grid = X_grid.to(device), y_grid.to(device)\n",
    "            \n",
    "            assert torch.equal(y_raw, y_grid), \"Both y must be equal\"\n",
    "            y = y_raw\n",
    "\n",
    "            # Forward pass\n",
    "            teacher_outputs = teacher_model(X_raw)\n",
    "            student_outputs = student_model(X_grid)\n",
    "\n",
    "            # Loss calculation\n",
    "            loss_teacher_hard = criterion_hard(teacher_outputs, y)\n",
    "            loss_student_hard = criterion_hard(student_outputs, y)\n",
    "\n",
    "            loss_soft = criterion_soft(\n",
    "                F.log_softmax(student_outputs / temperature, dim=1),\n",
    "                F.softmax(teacher_outputs / temperature, dim=1)\n",
    "            )\n",
    "\n",
    "            loss_student = alpha * loss_soft + (1 - alpha) * loss_student_hard\n",
    "            running_loss_student += loss_student.item()\n",
    "\n",
    "            # For teacher, we're interested in the hard loss only for monitoring\n",
    "            running_loss_teacher += loss_teacher_hard.item()\n",
    "\n",
    "            _, predicted_student = torch.max(student_outputs.data, 1)\n",
    "            _, predicted_teacher = torch.max(teacher_outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct_student += (predicted_student == y).sum().item()\n",
    "            correct_teacher += (predicted_teacher == y).sum().item()\n",
    "\n",
    "            # Update progress bar with the latest losses and accuracies\n",
    "            accuracy_student = 100 * correct_student / total\n",
    "            accuracy_teacher = 100 * correct_teacher / total\n",
    "            current_loss_student = running_loss_student / (i + 1)\n",
    "            current_loss_teacher = running_loss_teacher / (i + 1)\n",
    "            \n",
    "            progress_bar.set_postfix(Student_Loss=f'{current_loss_student:.4f}', Student_Accuracy=f'{accuracy_student:.2f}%', Teacher_Loss=f'{current_loss_teacher:.4f}', Teacher_Accuracy=f'{accuracy_teacher:.2f}%')\n",
    "\n",
    "    average_loss_student = running_loss_student / len(data_raw)\n",
    "    average_loss_teacher = running_loss_teacher / len(data_raw)\n",
    "    accuracy_student = 100 * correct_student / total\n",
    "    accuracy_teacher = 100 * correct_teacher / total\n",
    "    return average_loss_student, average_loss_teacher, accuracy_student, accuracy_teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████| 768/768 [00:27<00:00, 28.36it/s, Student_Accuracy=56.60%, Student_Loss=0.3637, Teacher_Accuracy=71.73%, Teacher_Loss=0.3104]\n",
      "Validation Epoch 0: 100%|██████████| 192/192 [00:06<00:00, 31.87it/s, Student_Accuracy=56.77%, Student_Loss=0.3712, Teacher_Accuracy=77.38%, Teacher_Loss=0.5231]\n",
      "Training Epoch 1: 100%|██████████| 768/768 [00:26<00:00, 28.86it/s, Student_Accuracy=60.22%, Student_Loss=0.3688, Teacher_Accuracy=82.13%, Teacher_Loss=0.2757]\n",
      "Validation Epoch 1: 100%|██████████| 192/192 [00:05<00:00, 36.45it/s, Student_Accuracy=63.47%, Student_Loss=0.3615, Teacher_Accuracy=80.38%, Teacher_Loss=0.4647]\n",
      "Training Epoch 2: 100%|██████████| 768/768 [00:28<00:00, 27.31it/s, Student_Accuracy=70.18%, Student_Loss=0.3451, Teacher_Accuracy=86.49%, Teacher_Loss=0.2553]\n",
      "Validation Epoch 2: 100%|██████████| 192/192 [00:04<00:00, 42.77it/s, Student_Accuracy=73.03%, Student_Loss=0.3332, Teacher_Accuracy=81.79%, Teacher_Loss=0.4250]\n",
      "Training Epoch 3: 100%|██████████| 768/768 [00:29<00:00, 26.30it/s, Student_Accuracy=79.06%, Student_Loss=0.3067, Teacher_Accuracy=89.10%, Teacher_Loss=0.2357]\n",
      "Validation Epoch 3: 100%|██████████| 192/192 [00:04<00:00, 43.58it/s, Student_Accuracy=77.16%, Student_Loss=0.3256, Teacher_Accuracy=82.55%, Teacher_Loss=0.4018]\n",
      "Training Epoch 4: 100%|██████████| 768/768 [00:28<00:00, 26.84it/s, Student_Accuracy=84.07%, Student_Loss=0.2724, Teacher_Accuracy=90.76%, Teacher_Loss=0.2188]\n",
      "Validation Epoch 4: 100%|██████████| 192/192 [00:04<00:00, 44.27it/s, Student_Accuracy=80.50%, Student_Loss=0.3279, Teacher_Accuracy=83.98%, Teacher_Loss=0.3733]\n",
      "Training Epoch 5: 100%|██████████| 768/768 [00:28<00:00, 26.83it/s, Student_Accuracy=87.76%, Student_Loss=0.2414, Teacher_Accuracy=91.79%, Teacher_Loss=0.2029]\n",
      "Validation Epoch 5: 100%|██████████| 192/192 [00:04<00:00, 38.80it/s, Student_Accuracy=81.68%, Student_Loss=0.3328, Teacher_Accuracy=84.80%, Teacher_Loss=0.3571]\n",
      "Training Epoch 6: 100%|██████████| 768/768 [00:29<00:00, 25.93it/s, Student_Accuracy=90.37%, Student_Loss=0.2138, Teacher_Accuracy=92.97%, Teacher_Loss=0.1862]\n",
      "Validation Epoch 6: 100%|██████████| 192/192 [00:05<00:00, 38.12it/s, Student_Accuracy=82.80%, Student_Loss=0.3390, Teacher_Accuracy=85.51%, Teacher_Loss=0.3536]\n",
      "Training Epoch 7: 100%|██████████| 768/768 [00:29<00:00, 26.26it/s, Student_Accuracy=92.01%, Student_Loss=0.1934, Teacher_Accuracy=93.64%, Teacher_Loss=0.1738]\n",
      "Validation Epoch 7: 100%|██████████| 192/192 [00:04<00:00, 38.66it/s, Student_Accuracy=84.20%, Student_Loss=0.3428, Teacher_Accuracy=85.56%, Teacher_Loss=0.3486]\n",
      "Training Epoch 8: 100%|██████████| 768/768 [00:27<00:00, 27.61it/s, Student_Accuracy=93.29%, Student_Loss=0.1778, Teacher_Accuracy=94.27%, Teacher_Loss=0.1630]\n",
      "Validation Epoch 8: 100%|██████████| 192/192 [00:04<00:00, 41.80it/s, Student_Accuracy=84.19%, Student_Loss=0.3433, Teacher_Accuracy=86.23%, Teacher_Loss=0.3435]\n",
      "Training Epoch 9: 100%|██████████| 768/768 [00:28<00:00, 26.71it/s, Student_Accuracy=94.04%, Student_Loss=0.1657, Teacher_Accuracy=94.82%, Teacher_Loss=0.1533]\n",
      "Validation Epoch 9: 100%|██████████| 192/192 [00:04<00:00, 41.41it/s, Student_Accuracy=84.80%, Student_Loss=0.3627, Teacher_Accuracy=86.25%, Teacher_Loss=0.3479]\n",
      "Testing: 100%|██████████| 240/240 [00:03<00:00, 70.50it/s, Accuracy=86.95%, Loss=0.3279]\n",
      "Testing: 100%|██████████| 240/240 [00:03<00:00, 70.36it/s, Accuracy=85.40%, Loss=0.3493] \n"
     ]
    }
   ],
   "source": [
    "data_raw_train = deap_raw_train\n",
    "data_raw_val = deap_raw_val\n",
    "data_raw_test = deap_raw_test\n",
    "\n",
    "data_grid_train = deap_grid_train\n",
    "data_grid_val = deap_grid_val\n",
    "data_grid_test = deap_grid_test\n",
    "\n",
    "teacher_model = deap_trainer\n",
    "student_model = FBCCNN(num_classes=2, in_channels=4, grid_size=(9, 9))\n",
    "\n",
    "# Lists to store metrics for each epoch\n",
    "train_losses_student = []\n",
    "train_losses_teacher = []\n",
    "train_accuracies_student = []\n",
    "train_accuracies_teacher = []\n",
    "val_losses_student = []\n",
    "val_losses_teacher = []\n",
    "val_accuracies_student = []\n",
    "val_accuracies_teacher = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Training\n",
    "    train_loss_student, train_loss_teacher, train_accuracy_student, train_accuracy_teacher = train_online_kd(epoch, teacher_model, student_model, data_raw_train, data_grid_train, temperature=1.0, alpha=0.5)\n",
    "    train_losses_student.append(train_loss_student)\n",
    "    train_losses_teacher.append(train_loss_teacher)\n",
    "    train_accuracies_student.append(train_accuracy_student)\n",
    "    train_accuracies_teacher.append(train_accuracy_teacher)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss_student, val_loss_teacher, val_accuracy_student, val_accuracy_teacher = validate_online_kd(epoch, teacher_model, student_model, data_raw_val, data_grid_val, temperature=1.0, alpha=0.5)\n",
    "    val_losses_student.append(val_loss_student)\n",
    "    val_losses_teacher.append(val_loss_teacher)\n",
    "    val_accuracies_student.append(val_accuracy_student)\n",
    "    val_accuracies_teacher.append(val_accuracy_teacher)\n",
    "\n",
    "# Testing\n",
    "test_loss_teacher, test_accuracy_teacher = test_model(teacher_model, data_raw_test)\n",
    "test_loss_student, test_accuracy_student = test_model(student_model, data_grid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEACHER\n",
      "[99.19637044270833, 98.91357421875, 98.699951171875, 98.65926106770833, 98.69588216145833, 98.67146809895833, 98.663330078125, 98.681640625, 98.85660807291667, 98.92578125]\n",
      "[84.11458333333333, 83.59375, 84.33430989583333, 83.92740885416667, 84.26106770833333, 83.82161458333333, 83.82975260416667, 84.1796875, 83.9599609375, 83.80533854166667]\n",
      "83.11848958333333\n",
      "STUDENT\n",
      "[44.038899739583336, 56.170654296875, 70.60750325520833, 79.88484700520833, 85.82763671875, 89.41853841145833, 91.86197916666667, 93.26578776041667, 94.46614583333333, 95.34912109375]\n",
      "[48.396809895833336, 62.605794270833336, 71.91569010416667, 76.09049479166667, 77.92154947916667, 80.28971354166667, 80.18391927083333, 82.08821614583333, 82.3486328125, 83.056640625]\n",
      "83.15755208333333\n"
     ]
    }
   ],
   "source": [
    "print(\"TEACHER\")\n",
    "print(train_accuracies_teacher)\n",
    "print(val_accuracies_teacher)\n",
    "print(test_accuracy_teacher)\n",
    "\n",
    "print(\"STUDENT\")\n",
    "print(train_accuracies_student)\n",
    "print(val_accuracies_student)\n",
    "print(test_accuracy_student)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
